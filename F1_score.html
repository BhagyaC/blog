<!DOCTYPE html>
<html lang="en">

<head>
  <link rel="icon" type="image/png" href="img/favicon.ico">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Bhagya's Blogs</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet" type="text/css">
  <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

  <!-- Custom styles for this template -->
  <link href="css/clean-blog.min.css" rel="stylesheet">

</head>

<body>

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand" href="index.html">Learn Do Share Repeat</a>
      <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        Menu
        <i class="fas fa-bars"></i>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="index.html">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="about.html">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="contact.html">Contact</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Page Header -->
  <header class="masthead" style="background-image: url('img/background/f1score.png')">
    <div class="overlay"></div>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <div class="post-heading">
            <h1>F1 Score</h1>
            <h3>A measure of test's accuracy<h3>
            <span class="meta">Posted by
              <a href="#">Bhagya C</a>
              on March 4, 2021</span>
          </div>
        </div>
      </div>
    </div>
  </header>

  <!-- Post Content -->
  <article>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <p><span style="font-weight: 500;">Training a machine learning model on an imbalanced dataset can introduce unique challenges to the learning problem. Imbalanced data typically refers to a classification problem where the number of observations per class is not equally distributed; often you'll have a large amount of data/observations for one class (referred to as the </span><em><span style="font-weight: 500;">majority class</span></em><span style="font-weight: 500;">), and much fewer observations for one or more other classes (referred to as the </span><em><span style="font-weight: 500;">minority classes</span></em><span style="font-weight: 500;">). For example, we are building a classifier to classify text-based essays as shortlisted or rejected - we likely have 4000 rejection for 1500 shortlisting that's quite an imbalance!&nbsp;</span></p>
<p><span style="font-weight: 500;">While creating a machine learning model we are trying to figure out the parameters that will allow us to correctly classify to the majority class. It can be seen that machine learning models are subjected to </span><strong>frequency bias </strong><span style="font-weight: 500;">in which they place more emphasis on learning from observations that occur more commonly.</span></p>
<p><span style="font-weight: 500;">When dealing with imbalanced data standard classification metrics do not adequately represent the model performance</span></p>
<p><strong>Precision</strong><span style="font-weight: 500;">: is defined as the fraction of valid predictions of essays to rejected (true positives) among all the essays which were predicted to be rejected</span></p>
<a href="#">
  <img class="img-fluid" src="img/f1/1.png" alt="">
</a>
<p><strong>Recall/sensitivity:</strong><span style="font-weight: 500;"> is defined as the fraction of the examples which is correctly predicted to belong to rejected over all the essays that truly rejected</span></p>
<a href="#">
  <img class="img-fluid" src="img/f1/2.png" alt="">
</a>
<p><span style="font-weight: 500;">We can combine these two values into one by calculating the </span><strong>F1 score</strong><span style="font-weight: 500;">.</span></p>
<a href="#">
  <img class="img-fluid" src="img/f1/3.png" alt="">
</a>

<p><span style="font-weight: 500;">We have better precision and recall for our models and hence a better F1 score (and what does that mean?)</span></p>

<p><span style="font-weight: 500;">In the case of imbalanced data classification- The accuracy of the model is basically the total number of correct predictions divided by the total number of predictions. The </span><span style="font-weight: 500;">precision</span><span style="font-weight: 500;"> of a class defines how</span><strong> trustable </strong><span style="font-weight: 500;">is the result when the model answers that a point belongs to that class. The </span><span style="font-weight: 500;">recall/sensitivity</span><span style="font-weight: 500;"> of a class expresses how </span><strong>well the model is able to detect</strong><span style="font-weight: 500;"> that class. The F1 score of a class is given by the harmonic mean of precision and recall.</span></p>

<p><span style="font-weight: 500;">For a given class, the different combinations of recall and precision have the following meanings :</span></p>
<ul>
<li style="font-weight: 500;"><span style="font-weight: 500;">high recall/sensitivity + high precision: the class is perfectly handled by the model</span></li>
<li style="font-weight: 500;"><span style="font-weight: 500;">low recall/sensitivity + high precision: the model can&rsquo;t detect the class well but is highly trustable when it does</span></li>
<li style="font-weight: 500;"><span style="font-weight: 500;">high recall/sensitivity + low precision: the class is well detected but the model also includes points of other classes in it</span></li>
<li style="font-weight: 500;"><span style="font-weight: 500;">low recall/sensitivity + low precision: the class is poorly handled by the model</span></li>
</ul>
<a href="#">
  <img class="img-fluid" src="img/f1/4.png" alt="">
  <img class="img-fluid" src="img/f1/5.png" alt="">
</a>
<p><span style="font-weight: 500;">In detail, we have data (1000 essays) classified all into the rejected class</span></p>
<p><span style="font-weight: 500;">ACCURACY = 9620+0/9620+380+0+0</span></p>
<p><span style="font-weight: 500;">REJECTED class precision = 9620/9620+380</span></p>
<p><span style="font-weight: 500;">SHORTLISTED class precision = 0/0+0 - mathematically impossible to calculate</span></p>
<p><span style="font-weight: 500;">REJECTED class recall/sensitivity= 9620/9620+0</span></p>
<p><span style="font-weight: 500;">SHORTLISTED class recall/sensitivity = 0/0+380</span></p>
<p><span style="font-weight: 500;">The accuracy is 96.2% as said earlier. The rejected class precision is 96.2% and the shortlisted class precision is not computable. The recall/sensitivity of the rejected class is 1.0 which is perfect (all the rejected essays have been labeled as such rejected itself). But the recall/sensitivity of the rejected class is 0.0 which is the worse case (shortlisted products were detected). Thus, we can conclude our model is not doing well for this shortlisted class. The F1 score is not computable for the shortlisted class and is 0.981 for the rejected class. In this example, our goal is to classify the essays equally efficiently in both classes, and looking at these values of the F1 score will indicate that we have to rethink our model. These metrics will prevent us from using a useless model.</span></p>

<p><span style="font-weight: 400;">We can start by giving an example dataset where there are 1000 values. Assume there are 999 rejections and 1 shortlisting. Imagine a case where the model just rejects everyone. The accuracy would be 99.9%, even though there is no ML. The high accuracy is because of an imbalanced dataset and not because the model is working. Accuracy does not take into account the fact that the model was not able to predict even a single shortlisting case correctly. This is where F1 score comes. Need your help in calculating the F1 score and further explaining how F1 score considers the fact that not even a single shortlisting is correct.</span></p>
<p><span style="font-weight: 500;">The accuracy is 99.9% (999/1000)&nbsp;</span></p>
<p><span style="font-weight: 500;">The model is 99.9 % precise in terms of rejecting an essay</span></p>
<p><span style="font-weight: 500;">100% recall/sensitive because it correctly detected all the rejection essays</span></p>
<p><span style="font-weight: 500;">But if we consider the cases of shortlisting an essay</span></p>
<p><span style="font-weight: 500;">The model&rsquo;s precision to classify a shortlisting essay cannot be </span><strong>determined </strong><span style="font-weight: 500;">because it never shortlisted any of the essays</span></p>
<p><strong>0%</strong><span style="font-weight: 500;"> sensitive because it failed to classify the shortlisted essay&nbsp;</span></p>
<p><span style="font-weight: 500;">F1 score of the model not computable for shortlisting class and which indicates issues of our model. If we were evaluating our model just based on the accuracy we would have used a wrong model for classification.</span></p>
<p><span style="font-weight: 500;">Consider an example: An text classification system, which classified essays to shortlisted or rejected</span></p>
<p><span style="font-weight: 400;">Total data points: 207</span></p>
<p><span style="font-weight: 400;"> Shortlisted: 72</span></p>
<p><span style="font-weight: 400;">Rejected: 145</span></p>
<p><span style="font-weight: 500;">Here the rejection rate is 145/207 = 70%</span></p>
<p><span style="font-weight: 500;">&nbsp;Imagine a case where there is no model and then we just say everyone is rejection.</span></p>
<p><span style="font-weight: 500;">The accuracy of the model is 70%</span></p>
<p><span style="font-weight: 500;">Now we will check the preciseness(how trustable the model is ?) for and sensitivity(how well the model is able to detect the correct prediction) for a shortlisted essay</span></p>
<p><span style="font-weight: 500;">The precision of the model towards rejection class is 70% and the model&rsquo;s ability to detect the rejected essay is 100%&nbsp;</span></p>
<p><span style="font-weight: 500;">We can&rsquo;t define the precision for classification towards shortlisting class since there is no essay has been shortlisted by the model</span></p>
<p><span style="font-weight: 500;">And the correctness towards classifying an essay to shortlisting class is 0%</span></p>
<p><span style="font-weight: 500;">And also the </span><strong>F1 score for the shortlisting class cannot be determined </strong><span style="font-weight: 500;">- which indicates that we are not considering the class shortlisting at all and which is a violation to our model&rsquo;s goal and hence it is a wrong model</span></p>
<p><span style="font-weight: 500;">Our algorithm classifies correctly reject 135 essays and correctly classify 6 essays, whereas, 56 got wrongly rejected and 10 got wrongly shortlisted</span></p>
<p><span style="font-weight: 500;">The preciseness of this model toward the rejection is 70% and the model&rsquo;s ability to detect the rejected essays are 93%</span></p>
<p><span style="font-weight: 500;">Similarly, the preciseness of this model toward the shortlisting essays is 38%</span></p>
<p><span style="font-weight: 500;">And the ability of the model to shortlist an essay is 1%</span></p>
<p><span style="font-weight: 500;">Which successfully balances to find relationships between the data to both rejection and the shortlisting classes with an F1 score of 0.8 for shortlisting class</span></p>
<p><br /><br /><br /></p>
           </div>
      </div>
    </div>
  </article>

  <hr>

  <!-- Footer -->
  <footer>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <ul class="list-inline text-center">
            <li class="list-inline-item">
              <a href="https://twitter.com/BhagyaC4">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://github.com/BhagyaC/">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://www.linkedin.com/in/bhagya-c/">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
          </ul>
          <p class="copyright text-muted">Copyright &copy; Bhagya's Website 2021</p>
        </div>
      </div>
    </div>
  </footer>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/clean-blog.min.js"></script>

</body>

</html>
